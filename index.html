<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>DarkPatterns-LLM</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" href="style.css">
</head>
<body>

<!-- HERO -->
<header class="hero">
  <div class="hero-content">
    <div class="hero-text">
      <h1>DarkPatterns-LLM</h1>

      <p class="tagline">
        A Multi-Layer Benchmark for Detecting Manipulative and Harmful AI Behavior
      </p>

      <p class="authors">
        Sadia Asif 路 Israel A. Rosales Laguan 路 Haris Khan 路
        Shumaila Asif 路 Muneeb Asif
      </p>

      <div class="hero-links">
        <a href="paper/darkpatterns_llm.pdf" target="_blank"> Paper</a>
        <a href="https://arxiv.org/abs/7113996" target="_blank">arXiv</a>
        <a href="https://github.com/sadia-sigma-lab/darkpatterns-llm" target="_blank">Code</a>
        <a href="https://github.com/sadia-sigma-lab/Benchmark-dataset-for-dark-patterns-in-llms"
           target="_blank">Dataset</a>
      </div>
    </div>

    <div class="hero-image">
      <img src="assets/hero_categories.png"
           alt="DarkPatterns-LLM dataset harm categories">
    </div>
  </div>
</header>


<!-- ABSTRACT -->
<section>
  <h2>Abstract</h2>
  <p>
    Large Language Models increasingly influence high-stakes decisions, yet existing safety
    benchmarks fail to capture subtle, psychologically manipulative behaviors. We introduce
    <strong>DarkPatterns-LLM</strong>, the first multi-dimensional benchmark designed to detect
    manipulative and harmful AI behavior across seven harm categories using a four-layer
    analytical pipeline. Our framework provides fine-grained, interpretable diagnostics
    beyond binary safety classification.
  </p>
</section>

<!-- CONTRIBUTIONS -->
<section>
  <h2>Key Contributions</h2>
  <div class="grid">
    <div class="card">
      <h3>Multi-Layer Evaluation</h3>
      <p>
        Four analytical layers spanning manipulation detection, stakeholder impact,
        temporal propagation, and risk alignment.
      </p>
    </div>
    <div class="card">
      <h3>Psychology-Grounded Taxonomy</h3>
      <p>
        Seven harm categories including autonomy, psychological, economic, and societal harm.
      </p>
    </div>
    <div class="card">
      <h3>Novel Metrics</h3>
      <p>
        MRI, CRS, SIAS, and THDS enable structured, explainable safety benchmarking.
      </p>
    </div>
    <div class="card">
      <h3>Model Diagnostics</h3>
      <p>
        Reveals systematic blindspots in autonomy harm detection and temporal reasoning.
      </p>
    </div>
  </div>
</section>

<!-- FRAMEWORK -->
<section>
  <h2>Framework Overview</h2>
  <img src="assets/fig1.png" alt="DarkPatterns-LLM Framework">
  <p class="caption">
    Four-layer pipeline: Multi-Granular Detection (MGD), Multi-Scale Intent Analysis (MSIAN),
    Threat Harmonization Protocol (THP), and Deep Contextual Risk Alignment (DCRA).
  </p>
</section>

<!-- DATASET -->
<section id="dataset">
  <h2>Dataset</h2>
  <p>
    We release <strong>DarkPatterns-LLM</strong>, a dataset of
    <strong>401 expert-annotated instructionresponse pairs</strong>
    covering seven categories of manipulative and harmful AI behavior.
  </p>

  <ul class="inline-list">
    <li>Legal / Power</li>
    <li>Psychological</li>
    <li>Emotional</li>
    <li>Physical</li>
    <li>Autonomy</li>
    <li>Economic</li>
    <li>Societal</li>
  </ul>

  <p>
    Each instance includes harmful and safe responses, expert rationales,
    and structured annotations to support fine-grained, explainable safety evaluation.
  </p>

  <p>
     <a href="https://github.com/sadia-sigma-lab/all-about-dark-patterns-in-llms"
    target="_blank"><strong>Download Dataset</strong></a>
  </p>
</section>


<!-- RESULTS -->
<section>
  <h2>Results Highlights</h2>
  <div class="grid">
    <div class="stat">
      <span class="number">89.7</span>
      <span class="label">Top MRI Score</span>
    </div>
    <div class="stat">
      <span class="number">7</span>
      <span class="label">Harm Categories</span>
    </div>
    <div class="stat">
      <span class="number">401</span>
      <span class="label">Annotated Samples</span>
    </div>
    <div class="stat">
      <span class="number">4</span>
      <span class="label">Evaluation Layers</span>
    </div>
  </div>

  <p class="note">
    All evaluated models show consistent weaknesses in autonomy harm detection and
    temporal harm propagation.
  </p>
</section>

<!-- CITATION -->
<section>
  <h2>Citation</h2>
  <pre>
@article{darkpatternsllm2025,
  title={DarkPatterns-LLM: A Multi-Layer Benchmark for Detecting Manipulative and Harmful AI Behavior},
  author={Asif, Sadia and Rosales Laguan, Israel Antonio and Khan, Haris and Asif, Shumaila and Asif, Muneeb},
  journal={arXiv preprint arXiv:7113996},
  year={2025}
}
  </pre>
</section>

<footer>
  <p>
    漏 2025 DarkPatterns-LLM Authors 路 Released under CC BY
  </p>
</footer>

</body>
</html>
